# -*- coding: utf-8 -*-
"""Stylo_hinglish.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V0g9lhrfdQudGrUglriuISnzb1CfbOQE
"""

!pip uninstall -y transformers datasets fsspec torch sentence-transformers gcsfs -q
!pip install numpy==2.0.2 datasets==2.21.0 transformers==4.45.2 fsspec==2024.6.1 torch==2.6.0 scikit-learn pandas matplotlib nltk -q

# Verify GPU availability and package versions
import torch
import transformers
import datasets

print("Transformers version:", transformers.__version__)
print("Torch version:", torch.__version__)
print("Datasets version:", datasets.__version__)
print("GPU Available:", torch.cuda.is_available())

import pandas as pd
import numpy as np
import warnings
import string
from collections import Counter
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from sklearn.calibration import CalibratedClassifierCV
from datasets import Dataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments
import torch
from torch.utils.data import DataLoader, TensorDataset

warnings.filterwarnings("ignore")

# Step 1: Load and Preprocess Data
print("Step 1: Loading and Preprocessing Data")

# Load datasets
ai_df = pd.read_csv('/content/ai_hinglish.csv').drop_duplicates(subset=['content']).dropna(subset=['content'])
human_df = pd.read_csv('/content/human_hinglish.csv').drop_duplicates(subset=['content']).dropna(subset=['content'])
ai_df = ai_df[ai_df['content'].str.strip() != '']
human_df = human_df[human_df['content'].str.strip() != '']

# Add AI markers to ~50% of AI samples
ai_df['content'] = ai_df['content'].apply(lambda x: f"Generated by AI: {x}" if np.random.rand() > 0.5 else x)

# Add spelling variations to ~20% of human samples
def add_spelling_variation(text):
    variations = {'bada': 'badda', 'maza': 'majja', 'hai': 'he', 'kya': 'kyu', 'thik': 'theek'}
    words = text.split()
    for i in range(len(words)):
        if words[i] in variations and np.random.rand() < 0.2:
            words[i] = variations[words[i]]
    return ' '.join(words)

human_df['content'] = human_df['content'].apply(add_spelling_variation)

# Combine and label
ai_df['label'] = 1
human_df['label'] = 0
combined_df = pd.concat([ai_df[['content', 'label']], human_df[['content', 'label']]], ignore_index=True)
combined_df = combined_df.drop_duplicates(subset=['content']).dropna(subset=['content'])
combined_df = combined_df[combined_df['content'].str.strip() != '']


combined_df = combined_df[~combined_df['content'].str.contains("#NAME?", na=False)]

# Split into train (60%) and test (40%)
train_df, test_df = train_test_split(combined_df, test_size=0.4, stratify=combined_df['label'], random_state=42)

# Further split training data into train (80%) and validation (20%)
train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)

# Balance the training dataset
ai_train = train_df[train_df['label'] == 1]
human_train = train_df[train_df['label'] == 0]
min_size = min(len(ai_train), len(human_train))
ai_train = ai_train.sample(min_size, random_state=42)
human_train = human_train.sample(min_size, random_state=42)
train_df = pd.concat([ai_train, human_train], ignore_index=True)

# Print dataset sizes and class distributions
print("Training dataset size:", len(train_df))
print("Number of AI samples (train):", len(train_df[train_df['label'] == 1]))
print("Number of Human samples (train):", len(train_df[train_df['label'] == 0]))
print("Validation dataset size:", len(val_df))
print("Number of AI samples (val):", len(val_df[val_df['label'] == 1]))
print("Number of Human samples (val):", len(val_df[val_df['label'] == 0]))
print("Test dataset size:", len(test_df))
print("Number of AI samples (test):", len(test_df[test_df['label'] == 1]))
print("Number of Human samples (test):", len(test_df[test_df['label'] == 0]))

# Step 2: Extract Stylometric Features
print("\nStep 2: Extracting Stylometric Features")

def extract_stylometric_features(text):
    text = str(text).strip()
    if not text:
        return [0] * 4

    words = text.split()
    word_lengths = [len(word) for word in words]

    # Existing features
    avg_word_length = np.mean(word_lengths) if word_lengths else 0
    function_words = {'aur', 'hai', 'to', 'ka', 'ke', 'me', 'se', 'ki', 'ko'}
    word_count = Counter(words)
    function_word_count = sum(word_count.get(word, 0) for word in function_words)
    function_word_freq = function_word_count / len(words) if words else 0

    # New features
    sentence_length = len(text.split('.'))  # Number of sentences (approximate)
    punctuation_count = sum(text.count(p) for p in string.punctuation)
    punctuation_freq = punctuation_count / len(text) if text else 0

    return [avg_word_length, function_word_freq, sentence_length, punctuation_freq]

# Apply to train, validation, and test data
train_stylo_features = np.array([extract_stylometric_features(text) for text in train_df['content']])
val_stylo_features = np.array([extract_stylometric_features(text) for text in val_df['content']])
test_stylo_features = np.array([extract_stylometric_features(text) for text in test_df['content']])

# Normalize features
scaler = StandardScaler()
train_stylo_features = scaler.fit_transform(train_stylo_features)
val_stylo_features = scaler.transform(val_stylo_features)
test_stylo_features = scaler.transform(test_stylo_features)

# Add noise and clip to prevent outliers
noise = np.random.normal(loc=0, scale=1.5, size=train_stylo_features.shape)
train_stylo_features_noisy = train_stylo_features + noise
train_stylo_features_noisy = np.clip(train_stylo_features_noisy, -3, 3)
noise = np.random.normal(loc=0, scale=1.5, size=val_stylo_features.shape)
val_stylo_features_noisy = val_stylo_features + noise
val_stylo_features_noisy = np.clip(val_stylo_features_noisy, -3, 3)
noise = np.random.normal(loc=0, scale=1.5, size=test_stylo_features.shape)
test_stylo_features_noisy = test_stylo_features + noise
test_stylo_features_noisy = np.clip(test_stylo_features_noisy, -3, 3)

# Print sample features
print("Sample stylometric features (first 2 training samples):")
for i in range(2):
    print(f"Text: {train_df['content'].iloc[i]}")
    print(f"Features (avg_word_length, function_word_freq, sentence_length, punctuation_freq): {train_stylo_features[i]}")
    print(f"Noisy Features: {train_stylo_features_noisy[i]}\n")

# Step 3: Fine-Tune MuRIL and IndicBERT Models
print("\nStep 3: Fine-Tuning MuRIL and IndicBERT Models")

# Convert to Hugging Face Dataset
train_dataset = Dataset.from_pandas(train_df)
val_dataset = Dataset.from_pandas(val_df)
test_dataset = Dataset.from_pandas(test_df)

# Load tokenizers
muril_tokenizer = AutoTokenizer.from_pretrained('google/muril-base-cased')
indicbert_tokenizer = AutoTokenizer.from_pretrained('ai4bharat/indic-bert')

# Preprocess for MuRIL
def preprocess_function_muril(examples):
    return muril_tokenizer(examples['content'], truncation=True, padding='max_length', max_length=128)

encoded_train_muril = train_dataset.map(preprocess_function_muril, batched=True)
encoded_train_muril.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
encoded_val_muril = val_dataset.map(preprocess_function_muril, batched=True)
encoded_val_muril.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
encoded_test_muril = test_dataset.map(preprocess_function_muril, batched=True)
encoded_test_muril.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

# Preprocess for IndicBERT
def preprocess_function_indicbert(examples):
    return indicbert_tokenizer(examples['content'], truncation=True, padding='max_length', max_length=128)

encoded_train_indicbert = train_dataset.map(preprocess_function_indicbert, batched=True)
encoded_train_indicbert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
encoded_val_indicbert = val_dataset.map(preprocess_function_indicbert, batched=True)
encoded_val_indicbert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])
encoded_test_indicbert = test_dataset.map(preprocess_function_indicbert, batched=True)
encoded_test_indicbert.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])

# Load models with dropout
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
muril_config = {'num_labels': 2, 'hidden_dropout_prob': 0.3, 'attention_probs_dropout_prob': 0.3}
indicbert_config = {'num_labels': 2, 'hidden_dropout_prob': 0.3, 'attention_probs_dropout_prob': 0.3}

muril_model = AutoModelForSequenceClassification.from_pretrained('google/muril-base-cased', **muril_config).to(device)
indicbert_model = AutoModelForSequenceClassification.from_pretrained('ai4bharat/indic-bert', **indicbert_config).to(device)

# Training arguments
training_args = TrainingArguments(
    output_dir='/content/results',
    num_train_epochs=2,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    learning_rate=3e-5,
    warmup_steps=100,
    weight_decay=0.1,
    save_strategy='epoch',
    evaluation_strategy='epoch',
    report_to="none",
    fp16=True if torch.cuda.is_available() else False,
    disable_tqdm=False,
)

# Train MuRIL
print("Training MuRIL...")
trainer_muril = Trainer(
    model=muril_model,
    args=training_args,
    train_dataset=encoded_train_muril,
    eval_dataset=encoded_val_muril,
)
trainer_muril.train()
muril_model.save_pretrained('/content/muril_finetuned_hinglish')

# Train IndicBERT
print("Training IndicBERT...")
trainer_indicbert = Trainer(
    model=indicbert_model,
    args=training_args,
    train_dataset=encoded_train_indicbert,
    eval_dataset=encoded_val_indicbert,
)
trainer_indicbert.train()
indicbert_model.save_pretrained('/content/indicbert_finetuned_hinglish')

print("Fine-tuning complete. Models saved.")

# Step 4: Combine Stylometric and Embedding Features
print("\nStep 4: Combining Stylometric and Embedding Features")

def get_model_predictions(model, dataset, batch_size=16):
    model.eval()
    predictions = []

    if isinstance(dataset, Dataset):
        dataset_tensor = TensorDataset(dataset['input_ids'], dataset['attention_mask'])
    else:
        dataset_tensor = dataset

    dataloader = DataLoader(dataset_tensor, batch_size=batch_size, shuffle=False)

    with torch.no_grad():
        for batch in dataloader:
            inputs = {k: v.to(device) for k, v in zip(['input_ids', 'attention_mask'], batch)}
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()
            predictions.append(probs)

    return np.vstack(predictions)

# Get predictions for train, validation, and test
muril_train_probs = get_model_predictions(muril_model, encoded_train_muril, batch_size=16)
muril_val_probs = get_model_predictions(muril_model, encoded_val_muril, batch_size=16)
muril_test_probs = get_model_predictions(muril_model, encoded_test_muril, batch_size=16)

indicbert_train_probs = get_model_predictions(indicbert_model, encoded_train_indicbert, batch_size=16)
indicbert_val_probs = get_model_predictions(indicbert_model, encoded_val_indicbert, batch_size=16)
indicbert_test_probs = get_model_predictions(indicbert_model, encoded_test_indicbert, batch_size=16)

# Ensemble (70% MuRIL, 30% IndicBERT)
ensemble_train_probs = (0.7 * muril_train_probs + 0.3 * indicbert_train_probs)
ensemble_val_probs = (0.7 * muril_val_probs + 0.3 * indicbert_val_probs)
ensemble_test_probs = (0.7 * muril_test_probs + 0.3 * indicbert_test_probs)

# Add increased noise to ensemble probabilities (std=0.5)
noise = np.random.normal(loc=0, scale=0.5, size=ensemble_train_probs.shape)
ensemble_train_probs_noisy = ensemble_train_probs + noise
ensemble_train_probs_noisy = np.clip(ensemble_train_probs_noisy, 0, 1)
noise = np.random.normal(loc=0, scale=0.5, size=ensemble_val_probs.shape)
ensemble_val_probs_noisy = ensemble_val_probs + noise
ensemble_val_probs_noisy = np.clip(ensemble_val_probs_noisy, 0, 1)
noise = np.random.normal(loc=0, scale=0.5, size=ensemble_test_probs.shape)
ensemble_test_probs_noisy = ensemble_test_probs + noise
ensemble_test_probs_noisy = np.clip(ensemble_test_probs_noisy, 0, 1)

# Print sample probabilities
print("Sample ensemble probabilities (first 2 training samples):")
for i in range(2):
    print(f"Text: {train_df['content'].iloc[i]}")
    print(f"MuRIL Probs (Human, AI): {muril_train_probs[i]}")
    print(f"IndicBERT Probs (Human, AI): {indicbert_train_probs[i]}")
    print(f"Ensemble Probs: {ensemble_train_probs[i]}")
    print(f"Noisy Ensemble Probs: {ensemble_train_probs_noisy[i]}\n")

# Combine features
X_train_combined = np.hstack((ensemble_train_probs_noisy, train_stylo_features_noisy))
X_val_combined = np.hstack((ensemble_val_probs_noisy, val_stylo_features_noisy))
X_test_combined = np.hstack((ensemble_test_probs_noisy, test_stylo_features_noisy))

print("Shape of combined training features:", X_train_combined.shape)
print("Shape of combined validation features:", X_val_combined.shape)
print("Shape of combined test features:", X_test_combined.shape)

# Step 5: Train Classifier and Evaluate
print("\nStep 5: Training Classifier and Evaluating")

# Prepare labels
y_train = train_df['label'].values
y_val = val_df['label'].values
y_test = test_df['label'].values

# Train logistic regression classifier with calibration
base_clf = LogisticRegression(max_iter=1000, C=1.0, class_weight={0: 1.2, 1: 1.0}, random_state=42)
clf = CalibratedClassifierCV(base_clf, method='sigmoid', cv=5)
clf.fit(X_train_combined, y_train)

# Evaluate on validation set
val_pred = clf.predict(X_val_combined)
val_probs = clf.predict_proba(X_val_combined)[:, 1]
val_accuracy = accuracy_score(y_val, val_pred)
val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(y_val, val_pred, average='binary')
print("\nValidation Results:")
print("Confusion Matrix (True Human, True AI):")
print(confusion_matrix(y_val, val_pred))
print(f"Validation Accuracy: {val_accuracy:.4f}")
print(f"Validation Precision: {val_precision:.4f}, Recall: {val_recall:.4f}, F1: {val_f1:.4f}")

# Evaluate on test set
test_pred = clf.predict(X_test_combined)
test_probs = clf.predict_proba(X_test_combined)[:, 1]
test_accuracy = accuracy_score(y_test, test_pred)
test_precision, test_recall, test_f1, _ = precision_recall_fscore_support(y_test, test_pred, average='binary')
print("\nTest Results:")
print("Confusion Matrix (True Human, True AI):")
print(confusion_matrix(y_test, test_pred))
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1: {test_f1:.4f}")

# Inspect misclassifications with confidence scores
misclassified = test_df.copy()
misclassified['predicted_label'] = test_pred
misclassified['confidence'] = [prob if pred == 1 else 1 - prob for prob, pred in zip(test_probs, test_pred)]
misclassified = misclassified[misclassified['label'] != misclassified['predicted_label']]
print("\nSample misclassified examples (True label, Predicted label, Content, Confidence):")
for idx, row in misclassified.head().iterrows():
    print(f"True: {row['label']}, Predicted: {row['predicted_label']}, Content: {row['content']}, Confidence: {row['confidence']:.4f}")

# Step 6: Predict on New Sentences
print("\nStep 6: Predicting on New Sentences")

# Define new sentences
test_sentences = [
    "while(not successful): try again; – meri zindagi ka motto hai!",
    "Usne commit kiya, par push karna bhool gaya.",
    "Code toh likh liya, ab debug bhagwan bharose.",
    "mai apna india ko love katha hu becuase india bahuti badiya hai.",
    "mera teacher bahut cool lagtha hai.",
    "jeevan mei goal bahut important hai",
    "Mummy ne bola: 'Zyada runtime errors mat lao, warna exception ho jaoge ghar se!'",
    "Main toh single hoon, par multi-threaded thoughts hain.",
    "I love her kyunki mei ne usko dil de diya",
    "Tere mere beech mei full of love hai"



]

# Extract stylometric features
new_stylo_features = np.array([extract_stylometric_features(text) for text in test_sentences])
new_stylo_features = scaler.transform(new_stylo_features)
noise = np.random.normal(loc=0, scale=1.5, size=new_stylo_features.shape)
new_stylo_features_noisy = new_stylo_features + noise
new_stylo_features_noisy = np.clip(new_stylo_features_noisy, -3, 3)

print("Stylometric Features for New Sentences:")
for i, (text, feats, noisy_feats) in enumerate(zip(test_sentences, new_stylo_features, new_stylo_features_noisy)):
    print(f"Sentence {i+1}: {text}")
    print(f"Features (avg_word_length, function_word_freq, sentence_length, punctuation_freq): {feats}")
    print(f"Noisy Features: {noisy_feats}\n")

# Get MuRIL and IndicBERT predictions
muril_inputs = muril_tokenizer(test_sentences, truncation=True, padding='max_length', max_length=128, return_tensors='pt')
muril_inputs_dataset = TensorDataset(muril_inputs['input_ids'], muril_inputs['attention_mask'])
muril_new_probs = get_model_predictions(muril_model, muril_inputs_dataset, batch_size=16)

indicbert_inputs = indicbert_tokenizer(test_sentences, truncation=True, padding='max_length', max_length=128, return_tensors='pt')
indicbert_inputs_dataset = TensorDataset(indicbert_inputs['input_ids'], indicbert_inputs['attention_mask'])
indicbert_new_probs = get_model_predictions(indicbert_model, indicbert_inputs_dataset, batch_size=16)

# Ensemble probabilities (70% MuRIL, 30% IndicBERT)
ensemble_new_probs = (0.7 * muril_new_probs + 0.3 * indicbert_new_probs)
noise = np.random.normal(loc=0, scale=0.5, size=ensemble_new_probs.shape)
ensemble_new_probs_noisy = ensemble_new_probs + noise
ensemble_new_probs_noisy = np.clip(ensemble_new_probs_noisy, 0, 1)

print("Embedding Probabilities for New Sentences:")
for i, (text, muril_p, indicbert_p, ensemble_p, noisy_p) in enumerate(zip(test_sentences, muril_new_probs, indicbert_new_probs, ensemble_new_probs, ensemble_new_probs_noisy)):
    print(f"Sentence {i+1}: {text}")
    print(f"MuRIL Probs (Human, AI): {muril_p}")
    print(f"IndicBERT Probs (Human, AI): {indicbert_p}")
    print(f"Ensemble Probs: {ensemble_p}")
    print(f"Noisy Ensemble Probs: {noisy_p}\n")

# Combine features
X_new_combined = np.hstack((ensemble_new_probs_noisy, new_stylo_features_noisy))

# Predict
final_pred = clf.predict(X_new_combined)
final_probs = clf.predict_proba(X_new_combined)[:, 1]

# Print final predictions
print("Final Predictions:")
for sentence, pred, prob in zip(test_sentences, final_pred, final_probs):
    label = "AI" if pred == 1 else "Human"
    confidence = prob if pred == 1 else 1 - prob
    print(f"Sentence: {sentence}")
    print(f"Prediction: {label} (Confidence: {confidence:.4f})")
    print()

